{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157508, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>create_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>user_total_tweets</th>\n",
       "      <th>user_likes_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.591219e+18</td>\n",
       "      <td>'Like a 1930s Dictator': Vitalik Buterin Lays ...</td>\n",
       "      <td>2022-11-11 23:59:59+00:00</td>\n",
       "      <td>For now, Earth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#ftx</td>\n",
       "      <td>johnmorganFL</td>\n",
       "      <td>630.0</td>\n",
       "      <td>28492.0</td>\n",
       "      <td>240872.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>like dictator vitalik buterin lay sam bankmanf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.591219e+18</td>\n",
       "      <td>ðŸ’¸ $1,000 #Giveaway ðŸ’¸\\n\\nWe'll select 10 winner...</td>\n",
       "      <td>2022-11-11 23:59:57+00:00</td>\n",
       "      <td>Panama</td>\n",
       "      <td>8866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ftx</td>\n",
       "      <td>KuKzNFT</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>4452.0</td>\n",
       "      <td>8272.0</td>\n",
       "      <td>giveaway select winner randomly award account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.591219e+18</td>\n",
       "      <td>#FTX crazy Shit! #Crypto https://t.co/2GO4X3u2pt</td>\n",
       "      <td>2022-11-11 23:59:55+00:00</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ftx</td>\n",
       "      <td>MeAndMySports</td>\n",
       "      <td>315.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>ftx crazy shit crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.591219e+18</td>\n",
       "      <td>Yo @SBF_FTX, draw me like one of your French g...</td>\n",
       "      <td>2022-11-11 23:59:53+00:00</td>\n",
       "      <td>London, England</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ftx</td>\n",
       "      <td>thedoc7er</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4541.0</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>draw like french girl ftxcrash ftx binance czb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.591219e+18</td>\n",
       "      <td>@BitcoinMagazine you you simpletons cant under...</td>\n",
       "      <td>2022-11-11 23:59:51+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#ftx</td>\n",
       "      <td>jesseypaul4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>simpleton understand crypto wallet like exodus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157503</th>\n",
       "      <td>1.591565e+18</td>\n",
       "      <td>ðŸ”´ WAR IN ðŸ‡ºðŸ‡¦: FRANCE 24 reporter @cntrentF24, w...</td>\n",
       "      <td>2022-11-12 22:52:11+00:00</td>\n",
       "      <td>Hauts de France ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ukraine</td>\n",
       "      <td>annetteashley61</td>\n",
       "      <td>10522.0</td>\n",
       "      <td>9603.0</td>\n",
       "      <td>437088.0</td>\n",
       "      <td>291392.0</td>\n",
       "      <td>war france reporter spend lot time report ukra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157504</th>\n",
       "      <td>1.591565e+18</td>\n",
       "      <td>People still celebrating in Kherson and I love...</td>\n",
       "      <td>2022-11-12 22:52:09+00:00</td>\n",
       "      <td>Belgrade, Serbia, Europe</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ukraine</td>\n",
       "      <td>svrhovac</td>\n",
       "      <td>222.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9174.0</td>\n",
       "      <td>16675.0</td>\n",
       "      <td>people celebrate kherson love bit ukraine kherson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157505</th>\n",
       "      <td>1.591565e+18</td>\n",
       "      <td>A remarkable story #Ukraine https://t.co/eeBLc...</td>\n",
       "      <td>2022-11-12 22:52:04+00:00</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ukraine</td>\n",
       "      <td>TimBarker10</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>5927.0</td>\n",
       "      <td>remarkable story ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157506</th>\n",
       "      <td>1.591565e+18</td>\n",
       "      <td>#Ukraine: Relief in liberated #Kherson after 8...</td>\n",
       "      <td>2022-11-12 22:52:02+00:00</td>\n",
       "      <td>ðŸ‡®ðŸ‡ªðŸ‡ªðŸ‡ºðŸ‡ºðŸ‡¦ðŸŽ®</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ukraine</td>\n",
       "      <td>Aontaithe2021</td>\n",
       "      <td>5001.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>392315.0</td>\n",
       "      <td>308109.0</td>\n",
       "      <td>ukraine relief liberated kherson month putin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157507</th>\n",
       "      <td>1.591564e+18</td>\n",
       "      <td>Drone Drops Grenade Directly on Russian Soldie...</td>\n",
       "      <td>2022-11-12 22:51:59+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#ukraine</td>\n",
       "      <td>vbl68</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>drone drop grenade directly russian soldier op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157508 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0       1.591219e+18  'Like a 1930s Dictator': Vitalik Buterin Lays ...   \n",
       "1       1.591219e+18  ðŸ’¸ $1,000 #Giveaway ðŸ’¸\\n\\nWe'll select 10 winner...   \n",
       "2       1.591219e+18   #FTX crazy Shit! #Crypto https://t.co/2GO4X3u2pt   \n",
       "3       1.591219e+18  Yo @SBF_FTX, draw me like one of your French g...   \n",
       "4       1.591219e+18  @BitcoinMagazine you you simpletons cant under...   \n",
       "...              ...                                                ...   \n",
       "157503  1.591565e+18  ðŸ”´ WAR IN ðŸ‡ºðŸ‡¦: FRANCE 24 reporter @cntrentF24, w...   \n",
       "157504  1.591565e+18  People still celebrating in Kherson and I love...   \n",
       "157505  1.591565e+18  A remarkable story #Ukraine https://t.co/eeBLc...   \n",
       "157506  1.591565e+18  #Ukraine: Relief in liberated #Kherson after 8...   \n",
       "157507  1.591564e+18  Drone Drops Grenade Directly on Russian Soldie...   \n",
       "\n",
       "                        create_at                       geo  retweet_count  \\\n",
       "0       2022-11-11 23:59:59+00:00            For now, Earth            0.0   \n",
       "1       2022-11-11 23:59:57+00:00                    Panama         8866.0   \n",
       "2       2022-11-11 23:59:55+00:00               Seattle, WA            0.0   \n",
       "3       2022-11-11 23:59:53+00:00           London, England            0.0   \n",
       "4       2022-11-11 23:59:51+00:00                       NaN            0.0   \n",
       "...                           ...                       ...            ...   \n",
       "157503  2022-11-12 22:52:11+00:00     Hauts de France ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º           20.0   \n",
       "157504  2022-11-12 22:52:09+00:00  Belgrade, Serbia, Europe         1041.0   \n",
       "157505  2022-11-12 22:52:04+00:00                  Guernsey            0.0   \n",
       "157506  2022-11-12 22:52:02+00:00                   ðŸ‡®ðŸ‡ªðŸ‡ªðŸ‡ºðŸ‡ºðŸ‡¦ðŸŽ®          189.0   \n",
       "157507  2022-11-12 22:51:59+00:00                       NaN            0.0   \n",
       "\n",
       "        like_count  hashtags         username  following  followers  \\\n",
       "0              1.0      #ftx     johnmorganFL      630.0    28492.0   \n",
       "1              0.0      #ftx          KuKzNFT      594.0     1014.0   \n",
       "2              0.0      #ftx    MeAndMySports      315.0      342.0   \n",
       "3              0.0      #ftx        thedoc7er     1513.0      296.0   \n",
       "4              1.0      #ftx      jesseypaul4      123.0       44.0   \n",
       "...            ...       ...              ...        ...        ...   \n",
       "157503         0.0  #ukraine  annetteashley61    10522.0     9603.0   \n",
       "157504         0.0  #ukraine         svrhovac      222.0      150.0   \n",
       "157505         0.0  #ukraine      TimBarker10     2668.0     1217.0   \n",
       "157506         0.0  #ukraine    Aontaithe2021     5001.0     2376.0   \n",
       "157507         0.0  #ukraine            vbl68       28.0       16.0   \n",
       "\n",
       "        user_total_tweets  user_likes_count  \\\n",
       "0                240872.0             111.0   \n",
       "1                  4452.0            8272.0   \n",
       "2                  3032.0            1572.0   \n",
       "3                  4541.0            3626.0   \n",
       "4                   317.0              81.0   \n",
       "...                   ...               ...   \n",
       "157503           437088.0          291392.0   \n",
       "157504             9174.0           16675.0   \n",
       "157505             3290.0            5927.0   \n",
       "157506           392315.0          308109.0   \n",
       "157507             2760.0              21.0   \n",
       "\n",
       "                                             cleaned_text  \n",
       "0       like dictator vitalik buterin lay sam bankmanf...  \n",
       "1        giveaway select winner randomly award account...  \n",
       "2                                   ftx crazy shit crypto  \n",
       "3       draw like french girl ftxcrash ftx binance czb...  \n",
       "4       simpleton understand crypto wallet like exodus...  \n",
       "...                                                   ...  \n",
       "157503  war france reporter spend lot time report ukra...  \n",
       "157504  people celebrate kherson love bit ukraine kherson  \n",
       "157505                           remarkable story ukraine  \n",
       "157506   ukraine relief liberated kherson month putin ...  \n",
       "157507  drone drop grenade directly russian soldier op...  \n",
       "\n",
       "[157508 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/cleaned.csv.gz', compression='gzip', low_memory=False, lineterminator='\\n')\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "clean_tweets = df.cleaned_text\n",
    "dim = 10\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(clean_tweets)]\n",
    "model = Doc2Vec(documents, vector_size=dim, window=2, min_count=1, workers=4)\n",
    "doc2vecs = []\n",
    "for i in range(len(clean_tweets)):\n",
    "    # https://stackoverflow.com/questions/31321209/doc2vec-how-to-get-document-vectors\n",
    "    doc2vecs.append(model.dv[i])\n",
    "df_doc = df.copy()\n",
    "df_doc[[str(i) for i in range(dim)]] = pd.DataFrame(doc2vecs, index=df.index)\n",
    "df_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc.to_csv('data/doc2vec_{}.csv.gz'.format(dim), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                          output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                          )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like dictator vitalik buterin lay sam bankmanfrie ftx\n",
      "tensor([-1.9123e-02,  1.7378e-01,  3.8837e-01, -1.0340e-01,  1.9767e-01,\n",
      "         1.0072e-02,  6.5882e-02, -9.6792e-02, -4.0863e-01, -1.1204e-01,\n",
      "         3.5201e-01, -1.2200e-01, -2.1609e-01,  1.9498e-01, -3.1077e-01,\n",
      "         1.0755e+00, -5.0756e-01,  2.1503e-01, -3.5640e-01, -3.9819e-02,\n",
      "         4.5718e-01, -3.0101e-02, -3.9029e-02,  1.6567e-01,  2.1629e-01,\n",
      "         4.8449e-01,  1.8809e-01,  3.2697e-01, -2.6692e-01,  2.1963e-01,\n",
      "         1.7477e-01,  7.2260e-02, -4.5889e-02, -3.6418e-01, -2.0349e-01,\n",
      "        -9.2414e-02,  1.4672e-01,  2.8624e-01, -1.1189e-01,  8.0000e-02,\n",
      "         3.1481e-03, -3.5444e-01, -2.3180e-01, -1.6364e-01, -1.2557e-01,\n",
      "        -4.3402e-01, -1.8824e-01, -1.0842e-01,  1.3400e-03, -8.3181e-01,\n",
      "        -7.1654e-01, -4.6065e-01, -3.4996e-01, -3.3587e-01,  1.8402e-01,\n",
      "         2.3870e-01,  1.4929e-02, -2.3184e-01, -1.7462e-02,  7.8871e-02,\n",
      "        -2.5795e-01, -1.0149e-01, -1.7114e-01, -2.1117e-01,  2.2362e-01,\n",
      "         2.6312e-03,  2.5462e-01,  2.5162e-01, -5.0978e-01,  3.0393e-01,\n",
      "        -6.1138e-02,  2.3140e-01, -1.4906e-01,  3.9068e-01,  3.2961e-01,\n",
      "        -4.6285e-01, -2.4011e-02,  6.8535e-01,  3.5550e-01, -5.6149e-02,\n",
      "         2.7303e-01, -6.9438e-02, -1.5108e-01,  6.7292e-02,  2.1205e-01,\n",
      "         1.2312e-02,  4.0258e-01,  4.3484e-01, -6.5946e-02,  6.1681e-01,\n",
      "        -1.9332e-01, -2.0559e-01, -2.1472e-01, -6.5835e-02,  7.9718e-02,\n",
      "        -1.6453e-01, -8.8294e-01, -5.5030e-03, -1.9660e-01,  1.6695e-01,\n",
      "         2.7700e-01,  1.1180e-01, -1.6644e-01, -3.5906e-01, -2.8623e-01,\n",
      "        -3.5726e-01, -1.7073e-01,  2.5592e-01, -6.2883e-02, -3.7886e-02,\n",
      "        -5.9376e-02,  1.4469e-01,  2.0813e-01,  3.0323e-01,  3.5519e-01,\n",
      "        -1.4120e-01,  1.4884e-01,  1.0363e-01,  2.0003e-01, -4.9617e-01,\n",
      "        -9.5124e-02,  2.0344e-01,  3.0102e-01,  4.8561e-01,  8.2113e-02,\n",
      "        -1.7109e-01, -8.8977e-02, -3.8213e-01,  2.8212e-01,  6.5585e-01,\n",
      "         5.7786e-01, -9.9895e-02, -2.0846e-01, -1.0840e-01, -1.8244e-01,\n",
      "         2.4001e-01, -1.1499e-01, -1.6527e-01, -3.2957e-01, -4.3812e-01,\n",
      "        -2.6143e-01,  1.5753e-01, -3.4188e-01,  8.8343e-02, -1.7757e-01,\n",
      "        -2.6394e-01, -3.8428e-01,  2.4393e-01,  3.8045e-01,  4.7944e-01,\n",
      "        -5.5813e-01,  8.6383e-02, -4.9850e-01,  1.8156e-01, -2.3447e-01,\n",
      "        -2.7086e-01, -1.5627e-01,  1.2240e-02,  2.7928e-01,  2.3553e-01,\n",
      "         3.0907e-01,  2.7862e-01,  1.4868e-01, -2.8257e-01,  2.0613e-01,\n",
      "        -7.6774e-01, -1.4895e-01, -6.0888e-02,  4.5634e-02, -1.3929e-01,\n",
      "         1.5783e-01, -2.6995e-01,  3.9685e-01,  2.6969e-02,  2.2718e-01,\n",
      "         6.0819e-01, -2.2633e-01,  4.3928e-02, -6.7364e-02,  7.9369e-01,\n",
      "        -4.4562e-01,  3.6623e-02, -6.8509e-02,  3.5596e-02,  4.6810e-01,\n",
      "         4.4967e-01,  1.2901e-01, -3.0311e-01,  1.2853e-01, -2.3088e-01,\n",
      "        -2.4082e-01,  5.6739e-02,  1.6706e-01, -4.7391e-01,  2.6851e-01,\n",
      "        -3.0684e-01,  4.8649e-01, -1.9097e-01,  1.3280e-01,  1.0720e-01,\n",
      "        -3.1325e-01, -1.7880e-01, -2.6973e-01, -2.3680e-01, -2.8788e-01,\n",
      "         8.4963e-01,  2.2720e-01, -1.4511e-01, -6.2029e-01, -3.7622e-02,\n",
      "         3.2702e-01,  1.5450e-01, -2.4518e-01, -3.0582e-02,  5.7945e-02,\n",
      "        -3.6036e-01,  1.3288e-01, -4.3911e-01,  3.3359e-01,  5.8010e-01,\n",
      "        -2.6489e-02, -1.2781e-01,  2.3926e-04, -1.7697e-01, -3.0220e-01,\n",
      "         9.5965e-01,  3.8789e-01, -5.4213e-01,  3.2658e-01,  3.9688e-02,\n",
      "        -3.7624e-02, -1.0911e-01,  2.6323e-01, -4.1139e-01, -3.3348e-01,\n",
      "         5.4653e-01, -1.2868e-01, -1.1094e-01, -2.7087e-01, -3.8615e-02,\n",
      "        -2.3367e-01,  1.6882e-01,  6.8540e-01, -1.0027e-01, -6.8923e-02,\n",
      "         5.3194e-01, -1.3020e-01, -3.3585e-01, -2.0831e-01,  3.5843e-02,\n",
      "        -2.0917e-01,  3.6180e-02, -2.2984e-01, -3.2757e-01,  1.1715e-01,\n",
      "        -3.3607e-01,  3.3055e-01, -3.2362e-01, -1.9597e-01, -1.9919e-01,\n",
      "         3.7466e-01, -1.8366e-01,  2.2325e-01,  5.6994e-02,  1.6985e-01,\n",
      "        -7.7593e-02,  3.9894e-02,  8.7382e-02,  3.7940e-01, -1.0090e-01,\n",
      "         8.8805e-02,  5.0262e-01,  4.2124e-02,  3.4484e-01,  1.4261e-01,\n",
      "         3.8141e-01,  2.3457e-01,  2.7913e-01, -6.7692e-02, -8.7860e-01,\n",
      "        -3.5521e-02, -2.1490e-02,  1.7595e-01,  5.2164e-01, -7.8619e-01,\n",
      "         1.8866e-01,  9.8787e-02, -6.6060e-02, -2.6652e-02, -3.5877e-01,\n",
      "        -3.2357e-01,  1.3972e-01, -3.0349e-01, -3.0766e-01,  6.0302e-01,\n",
      "        -3.3752e-01, -3.6802e-01, -1.3408e-01, -4.8771e-01, -6.8277e-01,\n",
      "        -2.1993e-01,  7.3878e-01,  1.3762e-02, -7.8178e-02,  5.8662e-01,\n",
      "        -2.7285e-01,  1.2023e-01, -3.6946e-01, -1.2581e+01, -1.6833e-01,\n",
      "         1.0732e-01, -2.7049e-01,  6.5202e-01, -5.6296e-01, -1.5039e-01,\n",
      "        -1.2475e-01, -4.8618e-01, -2.1657e-01, -1.1636e-01, -3.2242e-02,\n",
      "         2.8813e-01, -2.8130e-01,  6.5865e-02, -1.2263e-01, -9.5639e-02,\n",
      "        -8.9499e-02, -3.3810e-02,  1.1662e-01, -1.4733e-01, -4.7904e-01,\n",
      "         2.7562e-01, -5.0203e-01,  6.6551e-01, -3.0990e-01, -1.3478e-01,\n",
      "         5.0090e-01, -5.6361e-01, -3.8989e-01, -4.1186e-01,  2.2236e-02,\n",
      "         2.3145e-02,  5.9333e-01,  9.7135e-02, -5.7389e-01, -1.5828e-01,\n",
      "        -2.6837e-01,  1.5001e-01, -2.8681e-01, -7.2561e-02, -3.7358e-01,\n",
      "        -8.2192e-02,  8.9608e-02,  4.0602e-01,  6.3474e-02, -8.0077e-02,\n",
      "        -1.2595e-01, -4.9236e-01,  8.4919e-02, -2.2153e-01, -3.0316e-01,\n",
      "         2.4021e-01, -6.5847e-01,  3.5225e-01,  3.0116e-01,  1.3156e-01,\n",
      "         5.4091e-01, -3.7416e-01, -5.1692e-01,  9.2627e-02,  1.2420e-02,\n",
      "        -3.9194e-01,  3.1603e-01,  3.8937e-01,  2.4279e-01,  1.9010e-01,\n",
      "        -2.3727e-01, -1.6479e-01, -4.1955e-02, -1.9690e-01, -3.4759e-02,\n",
      "         3.5245e-01, -1.5360e+00, -5.5356e-02,  3.5141e-02,  3.4956e-02,\n",
      "         3.2289e-01, -5.3489e-02, -1.0418e-01, -5.6412e-01, -5.8657e-02,\n",
      "         2.9492e-01, -1.5035e-01, -5.7458e-01,  1.0015e-01, -2.9638e-01,\n",
      "        -3.8895e-01, -5.4679e-01,  3.6459e-01, -2.8865e-02, -2.7218e-01,\n",
      "         2.8295e-01,  2.2813e-02, -1.3349e-01, -3.4942e-01,  4.0334e-01,\n",
      "        -4.3662e-01,  4.1336e-01,  2.8193e-01, -4.9136e-02,  9.1724e-02,\n",
      "         1.0114e-01, -5.6482e-01,  2.7445e-01,  1.2640e-01, -2.7426e-01,\n",
      "         8.6021e-02,  1.1395e-01,  2.3787e-01,  6.4698e-01, -2.0163e-01,\n",
      "        -5.9175e-01, -3.2477e-01, -5.3931e-02, -4.6351e-01,  2.3473e-01,\n",
      "         1.9432e-01,  1.0148e-01,  1.9650e-01, -6.2052e-01,  1.6358e-01,\n",
      "        -7.0907e-01, -3.3019e-01,  7.4085e-02,  3.2838e-01, -2.0989e-01,\n",
      "         2.6740e-01, -4.3466e-01,  3.8849e-01,  3.2241e-02, -2.4136e-01,\n",
      "         2.4201e-01, -6.8702e-01, -8.1456e-02,  2.2563e-02,  2.7112e-01,\n",
      "        -4.6421e-01, -4.1444e-01, -4.0897e-01, -3.9288e-03, -2.0877e-01,\n",
      "         5.2852e-01,  5.8350e-01,  9.3629e-02, -5.1041e-02, -1.2294e-01,\n",
      "         4.9786e-01,  2.4657e-01,  3.0772e-01, -1.2548e-01, -4.4195e-01,\n",
      "         7.7426e-01, -4.4777e-01,  3.3774e-01,  2.6540e-01,  7.1282e-01,\n",
      "        -7.0902e-01, -2.2363e-01, -4.6185e-01,  4.2743e-01, -5.1562e-01,\n",
      "        -2.3421e-01,  1.0867e-01,  5.1482e-02,  3.4870e-01, -2.9048e-01,\n",
      "        -6.9512e-02,  1.4728e-01,  3.7149e-01,  6.3698e-02, -1.1438e-02,\n",
      "        -6.0947e-01,  6.0446e-02, -3.2883e-01,  5.7066e-01,  3.1052e-01,\n",
      "        -8.4284e-02, -2.2223e-01,  6.7796e-01,  1.5526e-01,  7.6612e-01,\n",
      "         5.3498e-01, -3.8771e-02,  6.1837e-01, -2.7698e-01,  5.6519e-02,\n",
      "        -2.2904e-02,  3.9109e-01, -2.1770e-02, -5.3450e-01,  5.9025e-01,\n",
      "        -2.7938e-01, -1.7343e-01, -5.0920e-03, -1.7692e-02, -3.8940e-02,\n",
      "        -2.6710e-01, -1.0693e-01,  9.8897e-01, -7.0034e-01, -1.8639e-01,\n",
      "         4.8744e-02,  2.0640e-01, -3.6826e-01,  4.7364e-01,  4.7534e-01,\n",
      "         2.5229e-01,  1.8831e-01, -4.4144e-01, -3.3279e-01, -1.0770e-01,\n",
      "        -2.2871e-01,  6.3327e-02, -2.0647e-01,  1.4611e-01,  2.4001e-01,\n",
      "         1.9692e-01, -6.8314e-01, -4.1335e-01, -6.9649e-02, -1.2803e-01,\n",
      "        -4.0728e-02,  1.9874e-01, -6.5381e-02,  2.6945e-01,  5.0988e-01,\n",
      "        -8.9646e-03, -4.1084e-01,  1.7851e-01, -1.4387e-01, -1.1900e+00,\n",
      "         4.1190e-01,  3.2335e-01, -2.8355e-01, -1.6327e-01,  2.7833e-01,\n",
      "         3.9821e-01,  3.8791e-01, -5.7233e-01,  1.2227e-01, -4.3932e-01,\n",
      "        -4.6007e-02, -3.5107e-01,  1.4420e-01, -2.7063e-01,  9.7138e-02,\n",
      "        -4.4541e-01,  4.4557e-02,  6.0145e-02,  4.5811e-02,  2.0631e-03,\n",
      "        -2.9366e-01, -5.6358e-01,  3.5909e-01, -3.8102e-01,  5.4963e-02,\n",
      "         3.5065e-01,  1.3366e-01,  2.3036e-01, -4.2539e-01,  6.0414e-02,\n",
      "        -1.6109e-01, -2.1032e-01, -5.4156e-01, -8.5955e-02,  6.1817e-01,\n",
      "         1.3325e-01, -3.5989e-01, -4.3252e-01, -6.9445e-02, -1.7474e-01,\n",
      "         4.4993e-01,  1.3389e-01, -1.6436e-01, -1.4070e-01, -4.4493e-01,\n",
      "         5.6237e-01, -1.9244e-01,  9.0438e-02, -5.5024e-02, -1.9081e-01,\n",
      "        -1.4936e-02,  1.4325e-02,  5.7792e-01, -4.1718e-01, -3.8949e-01,\n",
      "        -3.8268e-01, -1.8563e-01, -6.0259e-02,  3.5845e-01,  3.2225e-01,\n",
      "        -3.6023e-01, -2.6446e-01, -3.6075e-01,  2.6587e-01, -2.5755e-01,\n",
      "        -3.2272e-02,  2.9389e-02,  2.5865e-01, -7.3265e-02, -3.6212e-01,\n",
      "         4.8648e-01,  2.5284e-01,  1.3243e-01, -5.9923e-02, -9.7381e-02,\n",
      "        -7.4203e-01,  2.6446e-02,  1.0716e-01, -1.3914e-01,  1.0529e-02,\n",
      "         2.2853e-01,  1.8903e-01,  1.5263e-01, -5.8863e-01, -7.2060e-02,\n",
      "         1.4218e-01,  1.3401e-01, -2.3434e-01, -2.2358e-01,  4.3181e-02,\n",
      "         4.2385e-01,  9.0614e-02, -3.1817e-01,  3.8876e-01,  6.4380e-02,\n",
      "        -4.9434e-01,  9.1596e-02,  2.3910e-01, -3.4454e-01, -1.8940e-02,\n",
      "         8.4457e-03,  6.2554e-02,  3.4512e-01, -5.1764e-02, -9.1389e-02,\n",
      "         2.6007e-02,  3.6670e-01,  4.4704e-01, -1.8112e-01,  4.9612e-01,\n",
      "        -2.3803e-01,  4.4432e-02,  1.3592e-01, -5.2580e-01,  2.0309e-01,\n",
      "         8.4224e-02,  4.5414e-01,  3.4784e-01,  1.4358e-01, -1.3996e-01,\n",
      "        -1.6706e-01,  1.3678e-01,  2.1471e-01, -1.3317e-01, -1.7401e-01,\n",
      "         3.8545e-02, -2.1498e-01,  5.9386e-01,  3.5296e-01, -3.1822e-01,\n",
      "        -7.5614e-02, -2.0326e-01, -2.8308e-01,  9.3247e-03,  1.8583e-01,\n",
      "         2.7757e-01,  2.7317e-01,  1.0716e-01,  3.8866e-01, -5.6973e-02,\n",
      "         9.3553e-02,  3.8327e-01, -2.5382e-01, -4.2388e-02, -8.2263e-02,\n",
      "        -8.3979e-02, -2.3694e-01, -1.0043e-01, -1.4413e-01, -1.2650e-01,\n",
      "        -3.6394e-01, -1.4165e-01, -1.5681e-01, -4.7314e-01,  3.9047e-01,\n",
      "        -1.5425e-01, -4.5283e-01, -1.6903e-01, -3.5553e-01,  2.2609e-01,\n",
      "         5.5038e-02,  1.1623e-01,  1.8853e-01, -2.1484e-01,  9.4172e-03,\n",
      "         4.5376e-01,  1.7345e-01,  1.1765e-03, -3.6968e-02,  1.8590e-01,\n",
      "        -3.6572e-01, -2.1600e-01,  1.1197e-01, -3.3856e-01, -5.7475e-01,\n",
      "         4.4388e-01, -6.9673e-01,  2.0446e-01, -4.1491e-01,  2.8983e-01,\n",
      "         5.4068e-02,  3.4738e-01,  2.4971e-01,  2.0155e-01,  2.5238e-01,\n",
      "        -4.7641e-01, -3.0691e-01, -2.1659e-01, -2.4514e-01, -7.1414e-01,\n",
      "         1.3233e-01,  2.6702e-01,  3.3610e-01, -2.1538e-02, -4.6455e-01,\n",
      "         1.3210e-02, -1.2427e-01,  6.5854e-02, -5.5065e-02,  2.5466e-01,\n",
      "         2.3489e-01, -3.5871e-01, -3.2243e-01,  4.9789e-01, -3.2891e-02,\n",
      "        -3.3718e-01,  2.1978e-01,  4.0416e-02, -3.2692e-01,  2.1124e-01,\n",
      "         3.0768e-01,  2.5143e-02,  1.7743e-01, -5.5496e-01, -2.6202e-01,\n",
      "         3.7283e-01,  8.2675e-02, -4.8577e-01, -3.1840e-01, -2.8043e-01,\n",
      "         1.1438e-01,  2.3047e-01,  1.0593e-01, -7.3414e-02, -1.8144e-01,\n",
      "        -1.5445e-01, -3.0721e-01, -1.0718e-01])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "clean_tweets = df.cleaned_text\n",
    "# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#33-creating-word-and-sentence-vectors-from-hidden-states\n",
    "text = clean_tweets[0]\n",
    "print(text)\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "# Convert inputs to tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "    # Extract sentence vector\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    print(sentence_embedding)\n",
    "    print(sentence_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.019122883677482605,\n",
       " 0.17377856373786926,\n",
       " 0.3883650302886963,\n",
       " -0.10339684784412384,\n",
       " 0.197665736079216,\n",
       " 0.010072129778563976,\n",
       " 0.06588219851255417,\n",
       " -0.096791572868824,\n",
       " -0.4086305797100067,\n",
       " -0.11203958094120026,\n",
       " 0.3520124852657318,\n",
       " -0.12200314551591873,\n",
       " -0.21608702838420868,\n",
       " 0.1949787735939026,\n",
       " -0.3107700049877167,\n",
       " 1.0755492448806763,\n",
       " -0.5075608491897583,\n",
       " 0.21503065526485443,\n",
       " -0.35639500617980957,\n",
       " -0.03981926664710045,\n",
       " 0.4571835696697235,\n",
       " -0.030101289972662926,\n",
       " -0.03902944549918175,\n",
       " 0.16567257046699524,\n",
       " 0.2162877917289734,\n",
       " 0.4844854474067688,\n",
       " 0.18808609247207642,\n",
       " 0.32696640491485596,\n",
       " -0.2669205069541931,\n",
       " 0.21962547302246094,\n",
       " 0.17477089166641235,\n",
       " 0.07226046919822693,\n",
       " -0.04588892683386803,\n",
       " -0.3641769587993622,\n",
       " -0.2034926414489746,\n",
       " -0.09241367876529694,\n",
       " 0.1467154324054718,\n",
       " 0.28623998165130615,\n",
       " -0.11189183592796326,\n",
       " 0.08000017702579498,\n",
       " 0.0031481096521019936,\n",
       " -0.3544405996799469,\n",
       " -0.23180320858955383,\n",
       " -0.16363704204559326,\n",
       " -0.1255728155374527,\n",
       " -0.43401676416397095,\n",
       " -0.18824239075183868,\n",
       " -0.10841873288154602,\n",
       " 0.001340028247795999,\n",
       " -0.8318120241165161,\n",
       " -0.7165399789810181,\n",
       " -0.46065041422843933,\n",
       " -0.34995555877685547,\n",
       " -0.3358672261238098,\n",
       " 0.184019535779953,\n",
       " 0.2386990785598755,\n",
       " 0.014928527176380157,\n",
       " -0.2318415641784668,\n",
       " -0.017462454736232758,\n",
       " 0.07887100428342819,\n",
       " -0.2579539120197296,\n",
       " -0.10148721933364868,\n",
       " -0.1711374968290329,\n",
       " -0.2111741155385971,\n",
       " 0.22361589968204498,\n",
       " 0.002631157636642456,\n",
       " 0.25462138652801514,\n",
       " 0.2516157627105713,\n",
       " -0.5097793936729431,\n",
       " 0.3039328157901764,\n",
       " -0.06113849952816963,\n",
       " 0.2314014732837677,\n",
       " -0.1490635722875595,\n",
       " 0.3906811773777008,\n",
       " 0.3296138644218445,\n",
       " -0.4628540575504303,\n",
       " -0.02401071786880493,\n",
       " 0.6853471994400024,\n",
       " 0.35549619793891907,\n",
       " -0.05614924058318138,\n",
       " 0.27302929759025574,\n",
       " -0.06943777203559875,\n",
       " -0.15107525885105133,\n",
       " 0.06729242205619812,\n",
       " 0.21204841136932373,\n",
       " 0.012312289327383041,\n",
       " 0.40258219838142395,\n",
       " 0.43483608961105347,\n",
       " -0.06594592332839966,\n",
       " 0.6168051362037659,\n",
       " -0.19332373142242432,\n",
       " -0.2055944800376892,\n",
       " -0.21471713483333588,\n",
       " -0.06583481281995773,\n",
       " 0.07971762120723724,\n",
       " -0.16452568769454956,\n",
       " -0.8829372525215149,\n",
       " -0.005503018386662006,\n",
       " -0.1965959519147873,\n",
       " 0.16695266962051392,\n",
       " 0.27700456976890564,\n",
       " 0.11180069297552109,\n",
       " -0.16643771529197693,\n",
       " -0.35905712842941284,\n",
       " -0.2862337529659271,\n",
       " -0.3572595715522766,\n",
       " -0.17072679102420807,\n",
       " 0.2559218108654022,\n",
       " -0.06288252025842667,\n",
       " -0.037885647267103195,\n",
       " -0.0593760646879673,\n",
       " 0.14469105005264282,\n",
       " 0.2081313580274582,\n",
       " 0.30322980880737305,\n",
       " 0.35518786311149597,\n",
       " -0.14119668304920197,\n",
       " 0.14883704483509064,\n",
       " 0.10363414138555527,\n",
       " 0.20002563297748566,\n",
       " -0.49616891145706177,\n",
       " -0.09512358903884888,\n",
       " 0.20344454050064087,\n",
       " 0.30101752281188965,\n",
       " 0.48560667037963867,\n",
       " 0.08211299777030945,\n",
       " -0.1710885912179947,\n",
       " -0.08897704631090164,\n",
       " -0.3821314871311188,\n",
       " 0.2821165919303894,\n",
       " 0.6558494567871094,\n",
       " 0.5778554677963257,\n",
       " -0.09989513456821442,\n",
       " -0.20846252143383026,\n",
       " -0.10839672386646271,\n",
       " -0.18243911862373352,\n",
       " 0.24001440405845642,\n",
       " -0.11499082297086716,\n",
       " -0.16526608169078827,\n",
       " -0.3295735716819763,\n",
       " -0.43811994791030884,\n",
       " -0.26143449544906616,\n",
       " 0.15752901136875153,\n",
       " -0.3418777585029602,\n",
       " 0.0883430764079094,\n",
       " -0.17757084965705872,\n",
       " -0.26393505930900574,\n",
       " -0.3842838704586029,\n",
       " 0.24392633140087128,\n",
       " 0.3804529011249542,\n",
       " 0.47943687438964844,\n",
       " -0.5581278800964355,\n",
       " 0.0863833874464035,\n",
       " -0.49850279092788696,\n",
       " 0.1815635710954666,\n",
       " -0.23446711897850037,\n",
       " -0.2708578407764435,\n",
       " -0.1562734842300415,\n",
       " 0.012239539995789528,\n",
       " 0.2792806625366211,\n",
       " 0.23552919924259186,\n",
       " 0.30907315015792847,\n",
       " 0.2786170542240143,\n",
       " 0.14868377149105072,\n",
       " -0.28257235884666443,\n",
       " 0.20612525939941406,\n",
       " -0.7677446007728577,\n",
       " -0.14894980192184448,\n",
       " -0.060887660831213,\n",
       " 0.04563377797603607,\n",
       " -0.13928768038749695,\n",
       " 0.15783169865608215,\n",
       " -0.2699452340602875,\n",
       " 0.3968498408794403,\n",
       " 0.02696908451616764,\n",
       " 0.22717662155628204,\n",
       " 0.6081896424293518,\n",
       " -0.2263346016407013,\n",
       " 0.04392816871404648,\n",
       " -0.0673644170165062,\n",
       " 0.7936907410621643,\n",
       " -0.4456222653388977,\n",
       " 0.036622531712055206,\n",
       " -0.06850940734148026,\n",
       " 0.035596270114183426,\n",
       " 0.46809548139572144,\n",
       " 0.44966763257980347,\n",
       " 0.12901313602924347,\n",
       " -0.3031088411808014,\n",
       " 0.12853100895881653,\n",
       " -0.23087798058986664,\n",
       " -0.24082300066947937,\n",
       " 0.056739456951618195,\n",
       " 0.1670617163181305,\n",
       " -0.4739082455635071,\n",
       " 0.2685123383998871,\n",
       " -0.3068438470363617,\n",
       " 0.48648586869239807,\n",
       " -0.19096778333187103,\n",
       " 0.13279621303081512,\n",
       " 0.10720323771238327,\n",
       " -0.313249796628952,\n",
       " -0.17880281805992126,\n",
       " -0.2697311341762543,\n",
       " -0.23679673671722412,\n",
       " -0.287880539894104,\n",
       " 0.8496271967887878,\n",
       " 0.22719569504261017,\n",
       " -0.14510931074619293,\n",
       " -0.6202895641326904,\n",
       " -0.03762234002351761,\n",
       " 0.32701683044433594,\n",
       " 0.1544964760541916,\n",
       " -0.2451772391796112,\n",
       " -0.030581776052713394,\n",
       " 0.0579453706741333,\n",
       " -0.3603578805923462,\n",
       " 0.13287906348705292,\n",
       " -0.4391072690486908,\n",
       " 0.3335893452167511,\n",
       " 0.5800998210906982,\n",
       " -0.0264891404658556,\n",
       " -0.1278066188097,\n",
       " 0.0002392562455497682,\n",
       " -0.17696617543697357,\n",
       " -0.30220040678977966,\n",
       " 0.9596502184867859,\n",
       " 0.3878897428512573,\n",
       " -0.5421341061592102,\n",
       " 0.32658398151397705,\n",
       " 0.03968821465969086,\n",
       " -0.03762367367744446,\n",
       " -0.1091141402721405,\n",
       " 0.2632311284542084,\n",
       " -0.41138771176338196,\n",
       " -0.33348485827445984,\n",
       " 0.546527624130249,\n",
       " -0.12868371605873108,\n",
       " -0.1109376773238182,\n",
       " -0.27086639404296875,\n",
       " -0.038614992052316666,\n",
       " -0.23367415368556976,\n",
       " 0.1688184291124344,\n",
       " 0.6853976249694824,\n",
       " -0.10027474164962769,\n",
       " -0.06892329454421997,\n",
       " 0.5319390892982483,\n",
       " -0.1301952600479126,\n",
       " -0.33585360646247864,\n",
       " -0.2083079218864441,\n",
       " 0.03584316745400429,\n",
       " -0.20916874706745148,\n",
       " 0.0361795648932457,\n",
       " -0.2298373281955719,\n",
       " -0.32756921648979187,\n",
       " 0.1171470358967781,\n",
       " -0.3360689580440521,\n",
       " 0.3305530846118927,\n",
       " -0.32362255454063416,\n",
       " -0.19596700370311737,\n",
       " -0.199192613363266,\n",
       " 0.3746638596057892,\n",
       " -0.18365734815597534,\n",
       " 0.22325195372104645,\n",
       " 0.056993987411260605,\n",
       " 0.16985121369361877,\n",
       " -0.07759292423725128,\n",
       " 0.03989383950829506,\n",
       " 0.08738238364458084,\n",
       " 0.37940067052841187,\n",
       " -0.10089760273694992,\n",
       " 0.08880537748336792,\n",
       " 0.5026223659515381,\n",
       " 0.042123887687921524,\n",
       " 0.34484025835990906,\n",
       " 0.1426076740026474,\n",
       " 0.3814089000225067,\n",
       " 0.23456914722919464,\n",
       " 0.2791327238082886,\n",
       " -0.06769241392612457,\n",
       " -0.8786011934280396,\n",
       " -0.0355212576687336,\n",
       " -0.02148986980319023,\n",
       " 0.1759461909532547,\n",
       " 0.5216424465179443,\n",
       " -0.7861897349357605,\n",
       " 0.18865694105625153,\n",
       " 0.09878717362880707,\n",
       " -0.06605972349643707,\n",
       " -0.026652224361896515,\n",
       " -0.3587683141231537,\n",
       " -0.3235706686973572,\n",
       " 0.13971568644046783,\n",
       " -0.30349498987197876,\n",
       " -0.30765995383262634,\n",
       " 0.6030237078666687,\n",
       " -0.33752092719078064,\n",
       " -0.36802273988723755,\n",
       " -0.1340809166431427,\n",
       " -0.48770803213119507,\n",
       " -0.6827747821807861,\n",
       " -0.21993297338485718,\n",
       " 0.7387821674346924,\n",
       " 0.013762278482317924,\n",
       " -0.07817836105823517,\n",
       " 0.5866231322288513,\n",
       " -0.27284950017929077,\n",
       " 0.12023410946130753,\n",
       " -0.3694618046283722,\n",
       " -12.580912590026855,\n",
       " -0.16832885146141052,\n",
       " 0.10732397437095642,\n",
       " -0.2704913020133972,\n",
       " 0.6520170569419861,\n",
       " -0.5629625916481018,\n",
       " -0.15039202570915222,\n",
       " -0.12474849075078964,\n",
       " -0.48617732524871826,\n",
       " -0.21657004952430725,\n",
       " -0.11636317521333694,\n",
       " -0.03224177658557892,\n",
       " 0.2881261706352234,\n",
       " -0.2813005745410919,\n",
       " 0.06586475670337677,\n",
       " -0.12262912094593048,\n",
       " -0.09563854336738586,\n",
       " -0.0894993394613266,\n",
       " -0.03380952030420303,\n",
       " 0.1166248470544815,\n",
       " -0.14733009040355682,\n",
       " -0.4790370762348175,\n",
       " 0.27561891078948975,\n",
       " -0.5020291805267334,\n",
       " 0.6655113697052002,\n",
       " -0.30989503860473633,\n",
       " -0.13478216528892517,\n",
       " 0.5008978843688965,\n",
       " -0.5636103749275208,\n",
       " -0.3898858428001404,\n",
       " -0.4118593633174896,\n",
       " 0.022236330434679985,\n",
       " 0.023145390674471855,\n",
       " 0.5933293700218201,\n",
       " 0.09713468700647354,\n",
       " -0.5738937258720398,\n",
       " -0.15828445553779602,\n",
       " -0.26837030053138733,\n",
       " 0.1500101238489151,\n",
       " -0.2868117690086365,\n",
       " -0.07256093621253967,\n",
       " -0.3735765218734741,\n",
       " -0.08219160884618759,\n",
       " 0.08960805833339691,\n",
       " 0.40602371096611023,\n",
       " 0.06347354501485825,\n",
       " -0.08007742464542389,\n",
       " -0.1259528547525406,\n",
       " -0.49235662817955017,\n",
       " 0.08491924405097961,\n",
       " -0.22152571380138397,\n",
       " -0.30316320061683655,\n",
       " 0.2402067631483078,\n",
       " -0.6584739089012146,\n",
       " 0.3522533178329468,\n",
       " 0.30115845799446106,\n",
       " 0.13156263530254364,\n",
       " 0.5409136414527893,\n",
       " -0.3741556704044342,\n",
       " -0.5169230699539185,\n",
       " 0.09262656420469284,\n",
       " 0.012419931590557098,\n",
       " -0.3919353783130646,\n",
       " 0.31602752208709717,\n",
       " 0.38937410712242126,\n",
       " 0.24279123544692993,\n",
       " 0.19009946286678314,\n",
       " -0.23726977407932281,\n",
       " -0.16479210555553436,\n",
       " -0.04195456951856613,\n",
       " -0.19690142571926117,\n",
       " -0.03475869446992874,\n",
       " 0.352449506521225,\n",
       " -1.535983681678772,\n",
       " -0.055355899035930634,\n",
       " 0.03514088690280914,\n",
       " 0.034955963492393494,\n",
       " 0.32289132475852966,\n",
       " -0.05348947271704674,\n",
       " -0.10418456792831421,\n",
       " -0.5641237497329712,\n",
       " -0.05865676328539848,\n",
       " 0.2949189245700836,\n",
       " -0.15034839510917664,\n",
       " -0.5745757222175598,\n",
       " 0.10015281289815903,\n",
       " -0.2963847219944,\n",
       " -0.388950914144516,\n",
       " -0.5467910766601562,\n",
       " 0.3645859360694885,\n",
       " -0.02886461839079857,\n",
       " -0.2721822261810303,\n",
       " 0.2829500138759613,\n",
       " 0.022812653332948685,\n",
       " -0.13348667323589325,\n",
       " -0.3494240641593933,\n",
       " 0.4033415615558624,\n",
       " -0.4366162419319153,\n",
       " 0.4133557379245758,\n",
       " 0.2819300591945648,\n",
       " -0.04913591593503952,\n",
       " 0.09172436594963074,\n",
       " 0.10114146023988724,\n",
       " -0.564816415309906,\n",
       " 0.2744547128677368,\n",
       " 0.12639638781547546,\n",
       " -0.27426230907440186,\n",
       " 0.08602093160152435,\n",
       " 0.1139468401670456,\n",
       " 0.2378716766834259,\n",
       " 0.646975040435791,\n",
       " -0.2016269862651825,\n",
       " -0.5917548537254333,\n",
       " -0.32477396726608276,\n",
       " -0.05393125116825104,\n",
       " -0.4635125994682312,\n",
       " 0.23472949862480164,\n",
       " 0.19432333111763,\n",
       " 0.1014752984046936,\n",
       " 0.19649580121040344,\n",
       " -0.6205242276191711,\n",
       " 0.1635773926973343,\n",
       " -0.7090664505958557,\n",
       " -0.3301936984062195,\n",
       " 0.07408524304628372,\n",
       " 0.32838064432144165,\n",
       " -0.2098911553621292,\n",
       " 0.2674002945423126,\n",
       " -0.4346611797809601,\n",
       " 0.38849183917045593,\n",
       " 0.0322410948574543,\n",
       " -0.2413569837808609,\n",
       " 0.24200554192066193,\n",
       " -0.6870208382606506,\n",
       " -0.08145564794540405,\n",
       " 0.022562818601727486,\n",
       " 0.2711239457130432,\n",
       " -0.4642120897769928,\n",
       " -0.4144371449947357,\n",
       " -0.40896716713905334,\n",
       " -0.003928763791918755,\n",
       " -0.2087741196155548,\n",
       " 0.5285249352455139,\n",
       " 0.583499550819397,\n",
       " 0.09362932294607162,\n",
       " -0.051041435450315475,\n",
       " -0.12294474989175797,\n",
       " 0.49785980582237244,\n",
       " 0.2465728223323822,\n",
       " 0.30772075057029724,\n",
       " -0.1254764199256897,\n",
       " -0.4419538080692291,\n",
       " 0.7742588520050049,\n",
       " -0.4477684199810028,\n",
       " 0.33774179220199585,\n",
       " 0.26539790630340576,\n",
       " 0.712820291519165,\n",
       " -0.709020733833313,\n",
       " -0.22363123297691345,\n",
       " -0.46185302734375,\n",
       " 0.4274282455444336,\n",
       " -0.5156193375587463,\n",
       " -0.23421330749988556,\n",
       " 0.10867010802030563,\n",
       " 0.05148207023739815,\n",
       " 0.3486996293067932,\n",
       " -0.29048001766204834,\n",
       " -0.06951159238815308,\n",
       " 0.14728423953056335,\n",
       " 0.37148618698120117,\n",
       " 0.06369753181934357,\n",
       " -0.011438337154686451,\n",
       " -0.6094690561294556,\n",
       " 0.060445547103881836,\n",
       " -0.32882681488990784,\n",
       " 0.5706603527069092,\n",
       " 0.31051990389823914,\n",
       " -0.08428430557250977,\n",
       " -0.2222270965576172,\n",
       " 0.6779574751853943,\n",
       " 0.15525966882705688,\n",
       " 0.7661188244819641,\n",
       " 0.5349810123443604,\n",
       " -0.03877091407775879,\n",
       " 0.6183735728263855,\n",
       " -0.2769818603992462,\n",
       " 0.056519340723752975,\n",
       " -0.022903742268681526,\n",
       " 0.3910931944847107,\n",
       " -0.021770134568214417,\n",
       " -0.5344973206520081,\n",
       " 0.5902494788169861,\n",
       " -0.27937957644462585,\n",
       " -0.17342916131019592,\n",
       " -0.0050919754430651665,\n",
       " -0.01769213005900383,\n",
       " -0.03893962875008583,\n",
       " -0.26710352301597595,\n",
       " -0.10692571103572845,\n",
       " 0.9889660477638245,\n",
       " -0.7003363370895386,\n",
       " -0.1863919347524643,\n",
       " 0.04874370992183685,\n",
       " 0.20640403032302856,\n",
       " -0.3682596683502197,\n",
       " 0.473637193441391,\n",
       " 0.47533753514289856,\n",
       " 0.2522851824760437,\n",
       " 0.18830768764019012,\n",
       " -0.44144314527511597,\n",
       " -0.3327852487564087,\n",
       " -0.10770263522863388,\n",
       " -0.22870926558971405,\n",
       " 0.06332668662071228,\n",
       " -0.20647136867046356,\n",
       " 0.1461128294467926,\n",
       " 0.24000801146030426,\n",
       " 0.19692040979862213,\n",
       " -0.6831353902816772,\n",
       " -0.41335323452949524,\n",
       " -0.06964942812919617,\n",
       " -0.12802830338478088,\n",
       " -0.040728043764829636,\n",
       " 0.19873987138271332,\n",
       " -0.06538096815347672,\n",
       " 0.2694501280784607,\n",
       " 0.5098841190338135,\n",
       " -0.008964569307863712,\n",
       " -0.41084420680999756,\n",
       " 0.17851240932941437,\n",
       " -0.14387062191963196,\n",
       " -1.1899945735931396,\n",
       " 0.4119012951850891,\n",
       " 0.3233497738838196,\n",
       " -0.28354549407958984,\n",
       " -0.1632673144340515,\n",
       " 0.2783276438713074,\n",
       " 0.3982066512107849,\n",
       " 0.3879149854183197,\n",
       " -0.5723284482955933,\n",
       " 0.12226980924606323,\n",
       " -0.43931519985198975,\n",
       " -0.04600716754794121,\n",
       " -0.35106995701789856,\n",
       " 0.14420300722122192,\n",
       " -0.27063027024269104,\n",
       " 0.09713812172412872,\n",
       " -0.44541096687316895,\n",
       " 0.044556982815265656,\n",
       " 0.060144711285829544,\n",
       " 0.04581126943230629,\n",
       " 0.002063104184344411,\n",
       " -0.29365524649620056,\n",
       " -0.5635835528373718,\n",
       " 0.3590884804725647,\n",
       " -0.381022185087204,\n",
       " 0.05496300011873245,\n",
       " 0.3506517708301544,\n",
       " 0.13366393744945526,\n",
       " 0.23035849630832672,\n",
       " -0.42539182305336,\n",
       " 0.060414351522922516,\n",
       " -0.16108964383602142,\n",
       " -0.21031798422336578,\n",
       " -0.541558027267456,\n",
       " -0.08595527708530426,\n",
       " 0.6181742548942566,\n",
       " 0.13325490057468414,\n",
       " -0.3598944842815399,\n",
       " -0.4325235188007355,\n",
       " -0.06944507360458374,\n",
       " -0.1747410148382187,\n",
       " 0.4499284029006958,\n",
       " 0.1338905394077301,\n",
       " -0.16436347365379333,\n",
       " -0.140701025724411,\n",
       " -0.44492700695991516,\n",
       " 0.5623687505722046,\n",
       " -0.19244439899921417,\n",
       " 0.0904381275177002,\n",
       " -0.05502421781420708,\n",
       " -0.19080859422683716,\n",
       " -0.014936269260942936,\n",
       " 0.014324629679322243,\n",
       " 0.5779237747192383,\n",
       " -0.4171821177005768,\n",
       " -0.38948649168014526,\n",
       " -0.3826780915260315,\n",
       " -0.18562690913677216,\n",
       " -0.06025885045528412,\n",
       " 0.3584507703781128,\n",
       " 0.3222459852695465,\n",
       " -0.3602312207221985,\n",
       " -0.26445767283439636,\n",
       " -0.36074814200401306,\n",
       " 0.2658722400665283,\n",
       " -0.25754886865615845,\n",
       " -0.0322718471288681,\n",
       " 0.02938910387456417,\n",
       " 0.2586480677127838,\n",
       " -0.07326498627662659,\n",
       " -0.36212456226348877,\n",
       " 0.486481636762619,\n",
       " 0.2528436779975891,\n",
       " 0.1324325054883957,\n",
       " -0.05992349237203598,\n",
       " -0.09738094359636307,\n",
       " -0.7420337796211243,\n",
       " 0.02644600160419941,\n",
       " 0.10715848207473755,\n",
       " -0.13913875818252563,\n",
       " 0.010529017075896263,\n",
       " 0.22853170335292816,\n",
       " 0.18902501463890076,\n",
       " 0.15262748301029205,\n",
       " -0.5886342525482178,\n",
       " -0.07205982506275177,\n",
       " 0.14217780530452728,\n",
       " 0.13400769233703613,\n",
       " -0.23433783650398254,\n",
       " -0.2235822081565857,\n",
       " 0.04318120330572128,\n",
       " 0.4238477945327759,\n",
       " 0.09061449021100998,\n",
       " -0.31817173957824707,\n",
       " 0.38875555992126465,\n",
       " 0.06437981128692627,\n",
       " -0.4943386912345886,\n",
       " 0.09159603714942932,\n",
       " 0.23910221457481384,\n",
       " -0.3445352613925934,\n",
       " -0.018940359354019165,\n",
       " 0.008445732295513153,\n",
       " 0.06255386769771576,\n",
       " 0.3451191186904907,\n",
       " -0.05176380276679993,\n",
       " -0.09138883650302887,\n",
       " 0.026007026433944702,\n",
       " 0.3666973412036896,\n",
       " 0.44704413414001465,\n",
       " -0.18111538887023926,\n",
       " 0.49612346291542053,\n",
       " -0.23803041875362396,\n",
       " 0.04443192481994629,\n",
       " 0.13592195510864258,\n",
       " -0.5257965326309204,\n",
       " 0.2030891627073288,\n",
       " 0.08422372490167618,\n",
       " 0.4541352093219757,\n",
       " 0.3478369414806366,\n",
       " 0.14357735216617584,\n",
       " -0.13995668292045593,\n",
       " -0.16705502569675446,\n",
       " 0.13678085803985596,\n",
       " 0.2147083729505539,\n",
       " -0.13317489624023438,\n",
       " -0.17400763928890228,\n",
       " 0.0385449081659317,\n",
       " -0.2149789184331894,\n",
       " 0.5938590168952942,\n",
       " 0.3529599606990814,\n",
       " -0.31821903586387634,\n",
       " -0.07561438530683517,\n",
       " -0.20325890183448792,\n",
       " -0.28307709097862244,\n",
       " 0.009324714541435242,\n",
       " 0.18583329021930695,\n",
       " 0.2775663733482361,\n",
       " 0.27316999435424805,\n",
       " 0.1071644127368927,\n",
       " 0.3886585533618927,\n",
       " -0.05697251483798027,\n",
       " 0.09355323016643524,\n",
       " 0.3832675516605377,\n",
       " -0.2538246810436249,\n",
       " -0.0423884242773056,\n",
       " -0.08226330578327179,\n",
       " -0.0839793011546135,\n",
       " -0.2369365245103836,\n",
       " -0.10043173283338547,\n",
       " -0.14412644505500793,\n",
       " -0.12650473415851593,\n",
       " -0.36394214630126953,\n",
       " -0.14164698123931885,\n",
       " -0.15680642426013947,\n",
       " -0.4731360673904419,\n",
       " 0.3904746174812317,\n",
       " -0.154246523976326,\n",
       " -0.4528252184391022,\n",
       " -0.16903117299079895,\n",
       " -0.3555343449115753,\n",
       " 0.2260855734348297,\n",
       " 0.055038146674633026,\n",
       " 0.1162307858467102,\n",
       " 0.18853479623794556,\n",
       " -0.2148394137620926,\n",
       " 0.009417233988642693,\n",
       " 0.45376336574554443,\n",
       " 0.17345154285430908,\n",
       " 0.0011765486560761929,\n",
       " -0.03696770966053009,\n",
       " 0.18590041995048523,\n",
       " -0.36571621894836426,\n",
       " -0.21599546074867249,\n",
       " 0.11197184771299362,\n",
       " -0.33856016397476196,\n",
       " -0.5747478604316711,\n",
       " 0.4438839554786682,\n",
       " -0.6967347860336304,\n",
       " 0.2044629007577896,\n",
       " -0.4149107336997986,\n",
       " 0.28983253240585327,\n",
       " 0.05406849831342697,\n",
       " 0.3473754823207855,\n",
       " 0.2497096061706543,\n",
       " 0.20155447721481323,\n",
       " 0.2523789703845978,\n",
       " -0.47641125321388245,\n",
       " -0.3069104552268982,\n",
       " -0.2165936976671219,\n",
       " -0.24513745307922363,\n",
       " -0.7141392827033997,\n",
       " 0.13233332335948944,\n",
       " 0.2670242190361023,\n",
       " 0.33610105514526367,\n",
       " -0.02153763547539711,\n",
       " -0.46455276012420654,\n",
       " 0.013210127130150795,\n",
       " -0.12427012622356415,\n",
       " 0.06585424393415451,\n",
       " -0.055064935237169266,\n",
       " 0.2546613812446594,\n",
       " 0.23489198088645935,\n",
       " -0.3587075471878052,\n",
       " -0.32242804765701294,\n",
       " 0.4978935122489929,\n",
       " -0.032891158014535904,\n",
       " -0.33717989921569824,\n",
       " 0.21977642178535461,\n",
       " 0.04041587561368942,\n",
       " -0.32692259550094604,\n",
       " 0.21123531460762024,\n",
       " 0.3076756000518799,\n",
       " 0.02514333464205265,\n",
       " 0.17742674052715302,\n",
       " -0.554963231086731,\n",
       " -0.26202425360679626,\n",
       " 0.37282660603523254,\n",
       " 0.08267506957054138,\n",
       " -0.485769122838974,\n",
       " -0.3184031844139099,\n",
       " -0.2804268002510071,\n",
       " 0.1143818274140358,\n",
       " 0.23047147691249847,\n",
       " 0.10592581331729889,\n",
       " -0.07341381162405014,\n",
       " -0.18144309520721436,\n",
       " -0.1544450968503952,\n",
       " -0.3072119951248169,\n",
       " -0.10718496143817902]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e16b93334650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                     \u001b[0;31m# must have conforming columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot set a row with mismatched columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "bert = pd.DataFrame(columns=[str(i) for i in range(768)])\n",
    "df.loc[len(df)] = sentence_embedding.tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b99a0a5658745b3913ae05a5f7b8fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9835714b9c4001a240bc9ae9a541d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec232cefb724e7ea6b6aa3e402854f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c02b90c74342379640642396a77ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5274902c49a9495bb1bf07dbea6c9e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68d3bd333a7424c909eb013ad8b3a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd60d7224a0e48e8968c6d7c894ce5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805cba50a0d241438ee9e57b2f4f9169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a17f7683ed431f84abc101e693abc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020950fb65ff40978eca0b6d90ff632b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a121b913424341e69f21c21feb0bf61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf3e01ae3b49dc91761cb887df8859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9689f4d46a44178537028384fe78ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c8b05fbcfa4a12a2d51ba76322584f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: like dictator vitalik buterin lay sam bankmanfrie ftx\n",
      "Embedding: [-1.36781447e-02  2.46694293e-02 -1.31215274e-01 -5.15292399e-02\n",
      " -8.51958394e-02  9.22903698e-03  5.32923453e-02  2.34605558e-02\n",
      " -2.70742644e-02  3.11732925e-02  4.68179025e-02 -1.99802537e-02\n",
      " -2.63234302e-02  1.77390613e-02  7.10884249e-03 -3.16139124e-02\n",
      " -3.83237787e-02  1.10480145e-01 -4.51878179e-03 -1.94068756e-02\n",
      " -3.24127823e-02 -4.68800552e-02  4.06582654e-02 -1.59789454e-02\n",
      " -6.43941686e-02 -9.32335705e-02  7.06977248e-02 -5.06424569e-02\n",
      "  7.31871501e-02 -6.85119489e-03  3.22131589e-02  7.38647953e-03\n",
      " -2.21598917e-03  8.43738485e-03 -4.06829827e-02  3.74396332e-02\n",
      "  3.61758210e-02  6.07829727e-02 -1.10712452e-02 -9.36119556e-02\n",
      "  1.21169975e-02 -5.32565527e-02 -7.89043400e-03 -2.03219932e-02\n",
      "  1.41841052e-02 -5.78347705e-02 -7.30177835e-02  2.51041185e-02\n",
      "  2.17415560e-02  5.33508323e-03 -5.80064356e-02 -3.58689725e-02\n",
      "  3.38780321e-03 -1.26726273e-02  5.69498129e-02 -7.74800107e-02\n",
      "  2.52899751e-02  8.66312161e-03  4.79871631e-02 -5.03028221e-02\n",
      " -3.81813720e-02  5.72253130e-02 -1.40893413e-02 -8.63313004e-02\n",
      "  3.87063436e-02  4.32426631e-02 -2.02330649e-02  6.77445680e-02\n",
      " -8.97211488e-03  3.94444680e-03  4.49442938e-02 -1.07820906e-01\n",
      " -4.43959162e-02 -3.93574648e-02 -1.16216660e-01 -7.56503046e-02\n",
      "  1.27525236e-02  4.87802476e-02 -1.67882349e-02  6.43458031e-03\n",
      "  1.71937626e-02 -6.52699731e-04 -3.50469425e-02 -4.27665701e-03\n",
      " -2.21495912e-03  1.39286537e-02 -2.17671804e-02 -8.87486041e-02\n",
      "  1.16309822e-02  1.98004860e-03  6.70104995e-02  4.53580134e-02\n",
      "  5.72317727e-02 -2.70667449e-02  4.13304418e-02 -1.63381472e-02\n",
      "  1.39573999e-02  1.86987966e-02 -7.72675350e-02  6.82214126e-02\n",
      "  1.18101612e-02  2.17718985e-02 -8.21872056e-03  5.67386579e-03\n",
      " -4.41804826e-02  1.06953681e-02  2.87253391e-02 -6.52334914e-02\n",
      "  4.51137349e-02 -2.44396459e-02 -6.79244325e-02 -6.20884411e-02\n",
      "  1.13812694e-02  1.36904605e-03  9.44215804e-02 -1.25234406e-02\n",
      " -4.81195338e-02  2.43011992e-02 -9.65050608e-02 -1.58757158e-03\n",
      "  6.67030215e-02  2.55365577e-02 -1.31835818e-01  3.76138687e-02\n",
      "  2.55371872e-02  8.77731014e-03  1.06736064e-04  4.91125727e-33\n",
      "  1.12985075e-02 -3.33591253e-02 -3.53187062e-02  6.87426478e-02\n",
      "  8.50058813e-03  2.19182335e-02 -3.79816256e-02 -2.63965782e-02\n",
      "  2.77221366e-03  9.63316634e-02 -1.88706871e-02 -7.23804682e-02\n",
      " -7.12461695e-02 -1.80201344e-02  2.03099884e-02 -1.53994458e-02\n",
      " -6.96644783e-02 -5.36089763e-02 -1.62024429e-04  6.24885634e-02\n",
      " -2.24438757e-02  5.57934195e-02  4.58709374e-02 -2.46159844e-02\n",
      "  1.12488702e-01  9.66521539e-03  4.40707384e-03 -7.36412331e-02\n",
      "  1.09746836e-01  3.56619731e-02 -1.61273535e-02 -4.97055911e-02\n",
      " -8.46728459e-02 -3.26380096e-02  3.79676260e-02 -3.34471725e-02\n",
      " -4.35283706e-02 -5.98466620e-02 -7.43891671e-02  1.77727696e-02\n",
      "  3.13044526e-02  8.82479176e-03 -2.68648211e-02  2.43215673e-02\n",
      " -2.65818252e-03  5.22723570e-02  8.02117959e-02  2.47393511e-02\n",
      "  1.11029118e-01 -2.15914529e-02 -8.12481940e-02  4.66807093e-03\n",
      " -1.09722756e-01 -5.99382110e-02  2.99804490e-02 -3.08658350e-02\n",
      " -4.47283126e-02  9.58731920e-02  2.15724744e-02 -2.47721411e-02\n",
      "  1.58993453e-02 -5.37822135e-02 -4.28248346e-02  4.67814803e-02\n",
      "  3.26747051e-03 -6.81341365e-02 -3.64231840e-02  6.02886118e-02\n",
      " -5.86114153e-02 -5.24276309e-03  1.08569057e-03  1.85335856e-02\n",
      " -2.93089673e-02  1.96655318e-02 -1.30148515e-01 -7.04656634e-03\n",
      "  4.46940102e-02  1.94603968e-02 -6.87368587e-02  1.39705334e-02\n",
      " -3.05621624e-02  9.02063027e-02  8.72778893e-02 -1.69028826e-02\n",
      "  6.11195564e-02  5.75948283e-02  4.97728437e-02 -6.50592223e-02\n",
      "  3.64310928e-02  9.27745644e-03 -1.07163236e-01 -1.33217033e-02\n",
      "  9.15700793e-02  2.93642245e-02 -3.00291982e-02 -6.17455665e-33\n",
      " -1.10210873e-01 -1.16415136e-01  5.20620868e-03  8.66843201e-03\n",
      "  6.47609830e-02  4.70589772e-02 -4.35496643e-02  3.89822386e-02\n",
      "  4.37137894e-02  6.61479658e-04 -6.38305675e-03  1.90802999e-02\n",
      "  8.14557970e-02 -1.29100902e-03  6.33693188e-02  1.12103596e-02\n",
      "  9.03136656e-02  7.71666020e-02 -6.70047328e-02 -2.31347326e-02\n",
      "  3.06398119e-03  2.48383768e-02 -1.34053044e-02  6.49977401e-02\n",
      " -3.54501829e-02  4.33413386e-02 -1.21392002e-02  1.49841029e-02\n",
      " -9.23486054e-02  3.68881114e-02  9.06944200e-02 -1.63681787e-02\n",
      " -1.49938285e-01  3.97453681e-02 -1.02206983e-01 -4.49874252e-02\n",
      "  2.28644703e-02  5.58954887e-02 -3.51565406e-02  6.93266690e-02\n",
      " -4.63155098e-02 -6.50536036e-03  1.32189346e-02  6.72431011e-03\n",
      " -3.01603973e-02 -4.28503491e-02 -2.49166209e-02 -4.07990851e-02\n",
      " -2.61155912e-03 -8.42389166e-02  3.40947248e-02  4.13905568e-02\n",
      " -5.40096462e-02  2.45333035e-02 -2.74001900e-03  6.81751221e-03\n",
      "  3.03083509e-02 -1.33910337e-02  8.21722522e-02 -2.86162365e-02\n",
      " -1.44117530e-02 -3.48352604e-02  3.81840244e-02  6.82555959e-02\n",
      " -1.45998988e-02  2.11957488e-02  2.60193972e-03  6.34340644e-02\n",
      "  2.92730220e-02 -1.38904592e-02  7.97247365e-02 -9.50295776e-02\n",
      " -1.14141606e-01  9.33558345e-02 -5.12897521e-02  9.51963365e-02\n",
      " -4.93208729e-02  4.86225933e-02  8.96355882e-03 -5.14066108e-02\n",
      "  2.98289675e-02 -5.53846620e-02 -6.54222891e-02  2.62099109e-03\n",
      "  1.82328727e-02  3.30308899e-02  6.45965189e-02 -6.06352054e-02\n",
      "  7.18016699e-02 -2.57505216e-02  1.12675522e-02 -8.68685320e-02\n",
      "  3.70601900e-02  2.08518095e-02 -4.25372310e-02 -2.60024429e-08\n",
      " -2.69100480e-02 -1.98756568e-02 -1.17470883e-02 -2.76528411e-02\n",
      " -3.57760973e-02 -4.26176935e-02 -4.32053991e-02 -5.01079708e-02\n",
      " -5.46880178e-02  3.13691907e-02 -4.53320099e-03 -7.73516437e-03\n",
      " -5.51728830e-02 -3.40160653e-02  9.76726711e-02 -7.56862806e-03\n",
      "  4.36425284e-02  6.38815612e-02 -2.89674327e-02 -2.09098328e-02\n",
      "  3.52186300e-02  1.19067179e-02  4.46172373e-04 -2.48247670e-04\n",
      " -3.36837955e-02  7.14625269e-02  2.54533943e-02  4.30262014e-02\n",
      "  6.66199103e-02  1.05736576e-01  6.07498689e-04  6.22319132e-02\n",
      "  5.18965349e-03 -1.01003841e-01  9.35621839e-03  1.21217541e-01\n",
      "  8.96162838e-02 -3.87919620e-02 -1.65199451e-02  3.09476685e-02\n",
      "  1.94753753e-03  1.04421878e-03  6.79187775e-02  1.45489108e-02\n",
      "  3.12933549e-02 -2.12777704e-02  4.62506637e-02 -3.67654562e-02\n",
      "  6.48575351e-02 -1.60350166e-02  1.86019931e-02  4.69761305e-02\n",
      "  4.00091782e-02  4.97873835e-02  1.07619703e-01 -8.53758380e-02\n",
      " -1.63980927e-02  4.46351580e-02 -4.50519919e-02 -4.64624763e-02\n",
      "  8.73659104e-02 -1.97426286e-02  9.74763110e-02 -4.23819758e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = clean_tweets[:1]\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013678144663572311,\n",
       " 0.024669429287314415,\n",
       " -0.13121527433395386,\n",
       " -0.05152923986315727,\n",
       " -0.08519583940505981,\n",
       " 0.00922903697937727,\n",
       " 0.05329234525561333,\n",
       " 0.02346055582165718,\n",
       " -0.027074264362454414,\n",
       " 0.03117329254746437,\n",
       " 0.046817902475595474,\n",
       " -0.019980253651738167,\n",
       " -0.026323430240154266,\n",
       " 0.017739061266183853,\n",
       " 0.007108842488378286,\n",
       " -0.03161391243338585,\n",
       " -0.0383237786591053,\n",
       " 0.11048014461994171,\n",
       " -0.004518781788647175,\n",
       " -0.0194068755954504,\n",
       " -0.032412782311439514,\n",
       " -0.04688005521893501,\n",
       " 0.040658265352249146,\n",
       " -0.015978945419192314,\n",
       " -0.06439416855573654,\n",
       " -0.09323357045650482,\n",
       " 0.07069772481918335,\n",
       " -0.050642456859350204,\n",
       " 0.07318715006113052,\n",
       " -0.006851194892078638,\n",
       " 0.032213158905506134,\n",
       " 0.007386479526758194,\n",
       " -0.0022159891668707132,\n",
       " 0.008437384851276875,\n",
       " -0.04068298265337944,\n",
       " 0.037439633160829544,\n",
       " 0.03617582097649574,\n",
       " 0.06078297272324562,\n",
       " -0.011071245186030865,\n",
       " -0.0936119556427002,\n",
       " 0.012116997502744198,\n",
       " -0.053256552666425705,\n",
       " -0.007890434004366398,\n",
       " -0.02032199315726757,\n",
       " 0.014184105210006237,\n",
       " -0.057834770530462265,\n",
       " -0.07301778346300125,\n",
       " 0.025104118511080742,\n",
       " 0.021741556003689766,\n",
       " 0.005335083231329918,\n",
       " -0.05800643563270569,\n",
       " -0.03586897253990173,\n",
       " 0.0033878032118082047,\n",
       " -0.012672627344727516,\n",
       " 0.056949812918901443,\n",
       " -0.0774800106883049,\n",
       " 0.025289975106716156,\n",
       " 0.008663121610879898,\n",
       " 0.047987163066864014,\n",
       " -0.05030282214283943,\n",
       " -0.038181371986866,\n",
       " 0.057225313037633896,\n",
       " -0.014089341275393963,\n",
       " -0.08633130043745041,\n",
       " 0.03870634362101555,\n",
       " 0.04324266314506531,\n",
       " -0.020233064889907837,\n",
       " 0.06774456799030304,\n",
       " -0.008972114883363247,\n",
       " 0.003944446798413992,\n",
       " 0.044944293797016144,\n",
       " -0.10782090574502945,\n",
       " -0.044395916163921356,\n",
       " -0.039357464760541916,\n",
       " -0.11621665954589844,\n",
       " -0.07565030455589294,\n",
       " 0.012752523645758629,\n",
       " 0.04878024756908417,\n",
       " -0.016788234934210777,\n",
       " 0.006434580311179161,\n",
       " 0.017193762585520744,\n",
       " -0.0006526997312903404,\n",
       " -0.03504694253206253,\n",
       " -0.00427665701135993,\n",
       " -0.0022149591241031885,\n",
       " 0.013928653672337532,\n",
       " -0.021767180413007736,\n",
       " -0.08874860405921936,\n",
       " 0.011630982160568237,\n",
       " 0.001980048604309559,\n",
       " 0.06701049953699112,\n",
       " 0.04535801336169243,\n",
       " 0.05723177269101143,\n",
       " -0.02706674486398697,\n",
       " 0.04133044183254242,\n",
       " -0.016338147222995758,\n",
       " 0.013957399874925613,\n",
       " 0.0186987966299057,\n",
       " -0.07726753503084183,\n",
       " 0.06822141259908676,\n",
       " 0.011810161173343658,\n",
       " 0.021771898493170738,\n",
       " -0.008218720555305481,\n",
       " 0.0056738657876849174,\n",
       " -0.044180482625961304,\n",
       " 0.01069536805152893,\n",
       " 0.028725339099764824,\n",
       " -0.0652334913611412,\n",
       " 0.045113734900951385,\n",
       " -0.024439645931124687,\n",
       " -0.06792443245649338,\n",
       " -0.06208844110369682,\n",
       " 0.011381269432604313,\n",
       " 0.0013690460473299026,\n",
       " 0.09442158043384552,\n",
       " -0.012523440644145012,\n",
       " -0.04811953380703926,\n",
       " 0.02430119924247265,\n",
       " -0.0965050607919693,\n",
       " -0.0015875715762376785,\n",
       " 0.06670302152633667,\n",
       " 0.025536557659506798,\n",
       " -0.13183581829071045,\n",
       " 0.037613868713378906,\n",
       " 0.025537187233567238,\n",
       " 0.008777310140430927,\n",
       " 0.0001067360644810833,\n",
       " 4.911257274721765e-33,\n",
       " 0.011298507452011108,\n",
       " -0.03335912525653839,\n",
       " -0.035318706184625626,\n",
       " 0.06874264776706696,\n",
       " 0.00850058812648058,\n",
       " 0.02191823348402977,\n",
       " -0.03798162564635277,\n",
       " -0.026396578177809715,\n",
       " 0.0027722136583179235,\n",
       " 0.09633166342973709,\n",
       " -0.01887068711221218,\n",
       " -0.07238046824932098,\n",
       " -0.07124616950750351,\n",
       " -0.018020134419202805,\n",
       " 0.020309988409280777,\n",
       " -0.015399445779621601,\n",
       " -0.06966447830200195,\n",
       " -0.0536089763045311,\n",
       " -0.00016202442930079997,\n",
       " 0.06248856335878372,\n",
       " -0.022443875670433044,\n",
       " 0.05579341948032379,\n",
       " 0.045870937407016754,\n",
       " -0.02461598441004753,\n",
       " 0.11248870193958282,\n",
       " 0.009665215387940407,\n",
       " 0.004407073836773634,\n",
       " -0.07364123314619064,\n",
       " 0.10974683612585068,\n",
       " 0.0356619730591774,\n",
       " -0.01612735353410244,\n",
       " -0.049705591052770615,\n",
       " -0.08467284590005875,\n",
       " -0.03263800963759422,\n",
       " 0.03796762600541115,\n",
       " -0.03344717249274254,\n",
       " -0.043528370559215546,\n",
       " -0.0598466619849205,\n",
       " -0.07438916712999344,\n",
       " 0.017772769555449486,\n",
       " 0.03130445256829262,\n",
       " 0.008824791759252548,\n",
       " -0.02686482109129429,\n",
       " 0.02432156726717949,\n",
       " -0.0026581825222820044,\n",
       " 0.052272357046604156,\n",
       " 0.08021179586648941,\n",
       " 0.024739351123571396,\n",
       " 0.11102911829948425,\n",
       " -0.02159145288169384,\n",
       " -0.0812481939792633,\n",
       " 0.004668070934712887,\n",
       " -0.10972275584936142,\n",
       " -0.0599382109940052,\n",
       " 0.029980449005961418,\n",
       " -0.030865835025906563,\n",
       " -0.04472831264138222,\n",
       " 0.09587319195270538,\n",
       " 0.021572474390268326,\n",
       " -0.024772141128778458,\n",
       " 0.01589934527873993,\n",
       " -0.05378221347928047,\n",
       " -0.04282483458518982,\n",
       " 0.04678148031234741,\n",
       " 0.0032674705144017935,\n",
       " -0.0681341364979744,\n",
       " -0.03642318397760391,\n",
       " 0.06028861179947853,\n",
       " -0.058611415326595306,\n",
       " -0.005242763087153435,\n",
       " 0.0010856905719265342,\n",
       " 0.018533585593104362,\n",
       " -0.029308967292308807,\n",
       " 0.019665531814098358,\n",
       " -0.1301485151052475,\n",
       " -0.007046566344797611,\n",
       " 0.04469401016831398,\n",
       " 0.019460396841168404,\n",
       " -0.06873685866594315,\n",
       " 0.013970533385872841,\n",
       " -0.030562162399291992,\n",
       " 0.09020630270242691,\n",
       " 0.08727788925170898,\n",
       " -0.016902882605791092,\n",
       " 0.06111955642700195,\n",
       " 0.05759482830762863,\n",
       " 0.04977284371852875,\n",
       " -0.06505922228097916,\n",
       " 0.03643109276890755,\n",
       " 0.009277456440031528,\n",
       " -0.10716323554515839,\n",
       " -0.013321703299880028,\n",
       " 0.09157007932662964,\n",
       " 0.029364224523305893,\n",
       " -0.03002919815480709,\n",
       " -6.174556645446662e-33,\n",
       " -0.11021087318658829,\n",
       " -0.11641513556241989,\n",
       " 0.005206208676099777,\n",
       " 0.008668432012200356,\n",
       " 0.06476098299026489,\n",
       " 0.04705897718667984,\n",
       " -0.043549664318561554,\n",
       " 0.03898223862051964,\n",
       " 0.04371378943324089,\n",
       " 0.000661479658447206,\n",
       " -0.006383056752383709,\n",
       " 0.019080299884080887,\n",
       " 0.08145579695701599,\n",
       " -0.001291009015403688,\n",
       " 0.06336931884288788,\n",
       " 0.011210359632968903,\n",
       " 0.09031366556882858,\n",
       " 0.0771666020154953,\n",
       " -0.0670047327876091,\n",
       " -0.023134732618927956,\n",
       " 0.0030639811884611845,\n",
       " 0.02483837679028511,\n",
       " -0.01340530440211296,\n",
       " 0.06499774008989334,\n",
       " -0.03545018285512924,\n",
       " 0.04334133863449097,\n",
       " -0.01213920023292303,\n",
       " 0.014984102919697762,\n",
       " -0.0923486053943634,\n",
       " 0.036888111382722855,\n",
       " 0.09069442003965378,\n",
       " -0.01636817865073681,\n",
       " -0.14993828535079956,\n",
       " 0.03974536806344986,\n",
       " -0.10220698267221451,\n",
       " -0.044987425208091736,\n",
       " 0.02286447025835514,\n",
       " 0.05589548870921135,\n",
       " -0.03515654057264328,\n",
       " 0.06932666897773743,\n",
       " -0.0463155098259449,\n",
       " -0.00650536036118865,\n",
       " 0.013218934647738934,\n",
       " 0.006724310107529163,\n",
       " -0.03016039729118347,\n",
       " -0.042850349098443985,\n",
       " -0.024916620925068855,\n",
       " -0.040799085050821304,\n",
       " -0.0026115591172128916,\n",
       " -0.0842389166355133,\n",
       " 0.03409472480416298,\n",
       " 0.0413905568420887,\n",
       " -0.05400964617729187,\n",
       " 0.024533303454518318,\n",
       " -0.0027400190010666847,\n",
       " 0.006817512214183807,\n",
       " 0.030308350920677185,\n",
       " -0.013391033746302128,\n",
       " 0.08217225223779678,\n",
       " -0.02861623652279377,\n",
       " -0.014411753043532372,\n",
       " -0.03483526036143303,\n",
       " 0.0381840243935585,\n",
       " 0.06825559586286545,\n",
       " -0.01459989883005619,\n",
       " 0.021195748820900917,\n",
       " 0.002601939719170332,\n",
       " 0.06343406438827515,\n",
       " 0.02927302196621895,\n",
       " -0.013890459202229977,\n",
       " 0.0797247365117073,\n",
       " -0.09502957761287689,\n",
       " -0.11414160579442978,\n",
       " 0.09335583448410034,\n",
       " -0.05128975212574005,\n",
       " 0.09519633650779724,\n",
       " -0.049320872873067856,\n",
       " 0.04862259328365326,\n",
       " 0.008963558822870255,\n",
       " -0.0514066107571125,\n",
       " 0.02982896752655506,\n",
       " -0.05538466200232506,\n",
       " -0.06542228907346725,\n",
       " 0.00262099108658731,\n",
       " 0.01823287270963192,\n",
       " 0.03303088992834091,\n",
       " 0.0645965188741684,\n",
       " -0.06063520535826683,\n",
       " 0.07180166989564896,\n",
       " -0.025750521570444107,\n",
       " 0.011267552152276039,\n",
       " -0.0868685320019722,\n",
       " 0.03706018999218941,\n",
       " 0.02085180953145027,\n",
       " -0.042537230998277664,\n",
       " -2.6002442865546982e-08,\n",
       " -0.026910047978162766,\n",
       " -0.019875656813383102,\n",
       " -0.0117470882833004,\n",
       " -0.027652841061353683,\n",
       " -0.03577609732747078,\n",
       " -0.04261769354343414,\n",
       " -0.04320539906620979,\n",
       " -0.05010797083377838,\n",
       " -0.054688017815351486,\n",
       " 0.03136919066309929,\n",
       " -0.004533200990408659,\n",
       " -0.007735164370387793,\n",
       " -0.0551728829741478,\n",
       " -0.034016065299510956,\n",
       " 0.09767267107963562,\n",
       " -0.0075686280615627766,\n",
       " 0.04364252835512161,\n",
       " 0.06388156116008759,\n",
       " -0.02896743267774582,\n",
       " -0.020909832790493965,\n",
       " 0.035218629986047745,\n",
       " 0.011906717903912067,\n",
       " 0.00044617237290367484,\n",
       " -0.0002482476702425629,\n",
       " -0.03368379548192024,\n",
       " 0.07146252691745758,\n",
       " 0.025453394278883934,\n",
       " 0.04302620142698288,\n",
       " 0.06661991029977798,\n",
       " 0.10573657602071762,\n",
       " 0.0006074986886233091,\n",
       " 0.06223191320896149,\n",
       " 0.0051896534860134125,\n",
       " -0.10100384056568146,\n",
       " 0.00935621839016676,\n",
       " 0.12121754139661789,\n",
       " 0.08961628377437592,\n",
       " -0.0387919619679451,\n",
       " -0.016519945114850998,\n",
       " 0.030947668477892876,\n",
       " 0.0019475375302135944,\n",
       " 0.001044218777678907,\n",
       " 0.06791877746582031,\n",
       " 0.014548910781741142,\n",
       " 0.0312933549284935,\n",
       " -0.021277770400047302,\n",
       " 0.046250663697719574,\n",
       " -0.036765456199645996,\n",
       " 0.06485753506422043,\n",
       " -0.016035016626119614,\n",
       " 0.01860199309885502,\n",
       " 0.046976130455732346,\n",
       " 0.04000917822122574,\n",
       " 0.049787383526563644,\n",
       " 0.10761970281600952,\n",
       " -0.0853758379817009,\n",
       " -0.016398092731833458,\n",
       " 0.04463515803217888,\n",
       " -0.04505199193954468,\n",
       " -0.04646247625350952,\n",
       " 0.08736591041088104,\n",
       " -0.019742628559470177,\n",
       " 0.09747631102800369,\n",
       " -0.042381975799798965]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
