{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "split-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# examples partially taken from https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "coupled-grave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263499 entries, 0 to 263498\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 197962 non-null  object \n",
      " 1   text               197963 non-null  object \n",
      " 2   create_at          157508 non-null  object \n",
      " 3   geo                101815 non-null  object \n",
      " 4   retweet_count      157508 non-null  object \n",
      " 5   like_count         157508 non-null  object \n",
      " 6   hashtags           157508 non-null  object \n",
      " 7   username           157508 non-null  object \n",
      " 8   following          157508 non-null  float64\n",
      " 9   followers          157508 non-null  object \n",
      " 10  user_total_tweets  157507 non-null  float64\n",
      " 11  user_likes_count   157507 non-null  object \n",
      " 12  cleaned_text       157506 non-null  object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 26.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/cleaned.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "norwegian-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'create_at', 'geo', 'retweet_count', 'like_count',\n",
       "       'hashtags', 'username', 'following', 'followers', 'user_total_tweets',\n",
       "       'user_likes_count', 'cleaned_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "driven-detective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#ukraine          27000\n",
       "#covid            27000\n",
       "#christmas        26690\n",
       "#vegan            26651\n",
       "#climatechange    26089\n",
       "#ftx              24076\n",
       "Name: hashtags, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['hashtags']!='ShopParaTi') & (data['hashtags']!='22.0')]\n",
    "data['hashtags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "virgin-charity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 157506 entries, 0 to 263498\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 157506 non-null  object \n",
      " 1   text               157506 non-null  object \n",
      " 2   create_at          157506 non-null  object \n",
      " 3   geo                101812 non-null  object \n",
      " 4   retweet_count      157506 non-null  object \n",
      " 5   like_count         157506 non-null  object \n",
      " 6   hashtags           157506 non-null  object \n",
      " 7   username           157506 non-null  object \n",
      " 8   following          157506 non-null  float64\n",
      " 9   followers          157506 non-null  object \n",
      " 10  user_total_tweets  157506 non-null  float64\n",
      " 11  user_likes_count   157506 non-null  object \n",
      " 12  cleaned_text       157506 non-null  object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 16.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data[data['cleaned_text'].notna()]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "revolutionary-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157506/157506 [19:57<00:00, 131.49it/s]\n"
     ]
    }
   ],
   "source": [
    "num_noun = []\n",
    "num_verb = []\n",
    "num_adj = []\n",
    "num_adv = []\n",
    "total_length = []\n",
    "for n in tqdm(data['text']):\n",
    "    doc = nlp(n)\n",
    "    noun, verb, adj, adv, length = 0,0,0,0,0\n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        for token in sent:\n",
    "            length += 1\n",
    "            if token.pos_ == 'NOUN': noun += 1\n",
    "            elif token.pos_ == 'VERB': verb += 1\n",
    "            elif  token.pos_ == 'ADJ': adj += 1\n",
    "            elif  token.pos_ == 'ADV': adv += 1\n",
    "    num_noun.append(noun)\n",
    "    num_verb.append(verb)\n",
    "    num_adj.append(adj)\n",
    "    num_adv.append(adv)\n",
    "    total_length.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "wired-terrace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 157506 entries, 0 to 263498\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 157506 non-null  object \n",
      " 1   text               157506 non-null  object \n",
      " 2   create_at          157506 non-null  object \n",
      " 3   geo                101812 non-null  object \n",
      " 4   retweet_count      157506 non-null  float64\n",
      " 5   like_count         157506 non-null  float64\n",
      " 6   hashtags           157506 non-null  object \n",
      " 7   username           157506 non-null  object \n",
      " 8   following          157506 non-null  float64\n",
      " 9   followers          157506 non-null  float64\n",
      " 10  user_total_tweets  157506 non-null  float64\n",
      " 11  user_likes_count   157506 non-null  float64\n",
      " 12  cleaned_text       157506 non-null  object \n",
      " 13  num_noun           157506 non-null  int64  \n",
      " 14  num_vern           157506 non-null  int64  \n",
      " 15  num_adj            157506 non-null  int64  \n",
      " 16  num_adv            157506 non-null  int64  \n",
      " 17  total_length       157506 non-null  int64  \n",
      " 18  num_verb           157506 non-null  int64  \n",
      "dtypes: float64(6), int64(6), object(7)\n",
      "memory usage: 24.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data['num_noun']=num_noun\n",
    "data['num_verb']=num_verb\n",
    "data['num_adj']=num_adj\n",
    "data['num_adv']=num_adv\n",
    "data['total_length']=total_length\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "british-first",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'create_at', 'geo', 'retweet_count', 'like_count',\n",
       "       'username', 'following', 'followers', 'user_total_tweets',\n",
       "       'user_likes_count', 'cleaned_text', 'num_noun', 'num_vern', 'num_adj',\n",
       "       'num_adv', 'total_length', 'num_verb', 'hashtags_#christmas',\n",
       "       'hashtags_#climatechange', 'hashtags_#covid', 'hashtags_#ftx',\n",
       "       'hashtags_#ukraine', 'hashtags_#vegan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data=data, columns=['hashtags'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "answering-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 157506 entries, 0 to 263498\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   id                       157506 non-null  object \n",
      " 1   text                     157506 non-null  object \n",
      " 2   create_at                157506 non-null  object \n",
      " 3   geo                      101812 non-null  object \n",
      " 4   retweet_count            157506 non-null  float64\n",
      " 5   like_count               157506 non-null  float64\n",
      " 6   username                 157506 non-null  object \n",
      " 7   following                157506 non-null  float64\n",
      " 8   followers                157506 non-null  float64\n",
      " 9   user_total_tweets        157506 non-null  float64\n",
      " 10  user_likes_count         157506 non-null  float64\n",
      " 11  cleaned_text             157506 non-null  object \n",
      " 12  num_noun                 157506 non-null  int64  \n",
      " 13  num_vern                 157506 non-null  int64  \n",
      " 14  num_adj                  157506 non-null  int64  \n",
      " 15  num_adv                  157506 non-null  int64  \n",
      " 16  total_length             157506 non-null  int64  \n",
      " 17  num_verb                 157506 non-null  int64  \n",
      " 18  hashtags_#christmas      157506 non-null  uint8  \n",
      " 19  hashtags_#climatechange  157506 non-null  uint8  \n",
      " 20  hashtags_#covid          157506 non-null  uint8  \n",
      " 21  hashtags_#ftx            157506 non-null  uint8  \n",
      " 22  hashtags_#ukraine        157506 non-null  uint8  \n",
      " 23  hashtags_#vegan          157506 non-null  uint8  \n",
      "dtypes: float64(6), int64(6), object(6), uint8(6)\n",
      "memory usage: 23.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data[['retweet_count','like_count','following','followers','user_total_tweets','user_likes_count']] = data[['retweet_count','like_count','following','followers','user_total_tweets','user_likes_count']].astype('float')\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "sapphire-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['like_count(log)']=  np.log(data['like_count'])\n",
    "data['retweet_count(log)']=  np.log(data['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "driven-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_with_meta.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "graphic-activation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23308 entries, 0 to 263489\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   following                23308 non-null  float64\n",
      " 1   followers                23308 non-null  float64\n",
      " 2   user_total_tweets        23308 non-null  float64\n",
      " 3   user_likes_count         23308 non-null  float64\n",
      " 4   hashtags_#christmas      23308 non-null  uint8  \n",
      " 5   hashtags_#climatechange  23308 non-null  uint8  \n",
      " 6   hashtags_#covid          23308 non-null  uint8  \n",
      " 7   hashtags_#ftx            23308 non-null  uint8  \n",
      " 8   hashtags_#ukraine        23308 non-null  uint8  \n",
      " 9   hashtags_#vegan          23308 non-null  uint8  \n",
      " 10  retweet_count            23308 non-null  float64\n",
      " 11  like_count               23308 non-null  float64\n",
      " 12  retweet_count(log)       23308 non-null  float64\n",
      " 13  like_count(log)          23308 non-null  float64\n",
      " 14  num_noun                 23308 non-null  int64  \n",
      " 15  num_verb                 23308 non-null  int64  \n",
      " 16  num_adj                  23308 non-null  int64  \n",
      " 17  num_adv                  23308 non-null  int64  \n",
      " 18  total_length             23308 non-null  int64  \n",
      "dtypes: float64(8), int64(5), uint8(6)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "useful_columns = [\n",
    "    'following',\n",
    "    'followers', \n",
    "    'user_total_tweets',\n",
    "    'user_likes_count',\n",
    "    'hashtags_#christmas', \n",
    "    'hashtags_#climatechange',\n",
    "    'hashtags_#covid', \n",
    "    'hashtags_#ftx', \n",
    "    'hashtags_#ukraine',\n",
    "    'hashtags_#vegan',\n",
    "    'retweet_count', \n",
    "    'like_count',\n",
    "    'retweet_count(log)',\n",
    "    'like_count(log)',\n",
    "    'num_noun',\n",
    "    'num_verb',\n",
    "    'num_adj',\n",
    "    'num_adv',\n",
    "    'total_length'\n",
    "]\n",
    "\n",
    "baseline_features = [\n",
    "    'following',\n",
    "    'followers', \n",
    "    'user_total_tweets',\n",
    "    'user_likes_count',\n",
    "    'hashtags_#christmas', \n",
    "    'hashtags_#climatechange',\n",
    "    'hashtags_#covid', \n",
    "    'hashtags_#ftx', \n",
    "    'hashtags_#ukraine',\n",
    "    'hashtags_#vegan',\n",
    "]\n",
    "\n",
    "\n",
    "all_features = [\n",
    "    'following',\n",
    "    'followers', \n",
    "    'user_total_tweets',\n",
    "    'user_likes_count',\n",
    "    'hashtags_#christmas', \n",
    "    'hashtags_#climatechange',\n",
    "    'hashtags_#covid', \n",
    "    'hashtags_#ftx', \n",
    "    'hashtags_#ukraine',\n",
    "    'hashtags_#vegan',\n",
    "    'num_noun',\n",
    "    'num_verb',\n",
    "    'num_adj',\n",
    "    'num_adv',\n",
    "    'total_length'\n",
    "]\n",
    "data_metadata = data[useful_columns]\n",
    "data_metadata = data_metadata[data_metadata['like_count']!=0]\n",
    "# data_metadata = data_metadata[data_metadata['retweet_count']!=0]\n",
    "data_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "genuine-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, X_dev, y_train, y_dev):\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    prediction = knn.predict(X_dev)\n",
    "    knn_mse = mean_squared_error(y_dev, prediction)\n",
    "    knn_r2 = r2_score(y_dev, prediction)\n",
    "    return knn_mse, knn_r2\n",
    "\n",
    "\n",
    "def svr(X_train, X_dev, y_train, y_dev):\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    prediction = svr.predict(X_dev)\n",
    "    svc_mse = mean_squared_error(y_dev, prediction)\n",
    "    svr_r2 = r2_score(y_dev, prediction)\n",
    "    return svc_mse, svr_r2\n",
    "\n",
    "# XGBRegressor\n",
    "def xgbr(X_train, X_dev, y_train, y_dev):\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', random_state=0, n_estimators = 50)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    xg_preds = xg_reg.predict(X_dev)\n",
    "    xg_mse = mean_squared_error(y_dev, xg_preds)\n",
    "    xg_r2 = r2_score(y_dev, xg_preds)\n",
    "    \n",
    "#     # Mean Squared Error\n",
    "#     xg_mse = mean_squared_error(np.e ** y_dev, np.e ** xg_preds)\n",
    "\n",
    "#     # r2 score\n",
    "#     xg_r2 = r2_score(np.e ** y_dev, np.e ** xg_preds)\n",
    "\n",
    "    return xg_mse, xg_r2\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "def gbr(X_train, X_dev, y_train, y_dev):\n",
    "    gra_reg = GradientBoostingRegressor(random_state=0, n_estimators = 50)\n",
    "    gra_reg.fit(X_train,y_train)\n",
    "    gra_preds = gra_reg.predict(X_dev)\n",
    "    gra_mse = mean_squared_error(y_dev, gra_preds)\n",
    "    gra_r2 = r2_score(y_dev, gra_preds)\n",
    "    return gra_mse, gra_r2\n",
    "\n",
    "# AdaBoostRegressor\n",
    "def ada(X_train, X_dev, y_train, y_dev):\n",
    "    ada_reg = AdaBoostRegressor(random_state=0, n_estimators = 50)\n",
    "    ada_reg.fit(X_train,y_train)\n",
    "    ada_preds = ada_reg.predict(X_dev)\n",
    "    ada_mse = mean_squared_error(y_dev, ada_preds)\n",
    "    ada_r2 = r2_score(y_dev, ada_preds)\n",
    "    return ada_mse, ada_r2\n",
    "\n",
    "def lasso(X_train, X_dev, y_train, y_dev):\n",
    "   \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    prediction = lasso.predict(X_dev)\n",
    "    lasso_mse = mean_squared_error(y_dev.values, prediction)\n",
    "    lasso_r2 = r2_score(y_dev, prediction)\n",
    "    return lasso_mse, lasso_r2\n",
    "\n",
    "def ridge(X_train, X_dev, y_train, y_dev):\n",
    "   \n",
    "    ridge = Ridge()\n",
    "    ridge.fit(X_train, y_train)\n",
    "    prediction = ridge.predict(X_dev)\n",
    "    ridge_mse = mean_squared_error(y_dev, prediction)\n",
    "    ridge_r2 = r2_score(y_dev, prediction)\n",
    "    return ridge_mse, ridge_r2\n",
    "\n",
    "\n",
    "# Linear regression\n",
    "def linreg(X_train, X_dev, y_train, y_dev):\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    prediction = linreg.predict(X_dev)\n",
    "    linreg_mse = mean_squared_error(y_dev, prediction)\n",
    "    linreg_r2 = r2_score(y_dev, prediction)\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    lm_mse = mean_squared_error(np.e ** y_dev, np.e ** prediction)\n",
    "\n",
    "    # r2 score\n",
    "    lm_r2 = r2_score(np.e ** y_dev, np.e ** prediction)\n",
    "    \n",
    "#     return linreg_mse, linreg_r2\n",
    "    return lm_mse, lm_r2\n",
    "\n",
    "\n",
    "# Random Forests\n",
    "def rf(X_train, X_dev, y_train, y_dev):\n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    rf.fit(X_train,y_train)\n",
    "    prediction = rf.predict(X_dev)\n",
    "    rf_mse = mean_squared_error(y_dev, prediction)\n",
    "    rf_r2 = r2_score(y_dev, prediction)\n",
    "    \n",
    "    \n",
    "    # Mean Squared Error\n",
    "#     rf_mse = mean_squared_error(np.e ** y_dev, np.e ** prediction)\n",
    "\n",
    "#     # r2 score\n",
    "#     rf_r2 = r2_score(np.e ** y_dev, np.e ** prediction)\n",
    "    \n",
    "    return rf_mse, rf_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "tutorial-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1462728778077955"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data_metadata[all_features]\n",
    "labels = data_metadata['like_count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "prediction = rf.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, prediction)\n",
    "rf_r2 = r2_score(y_test, prediction)\n",
    "mean_squared_log_error(y_test, rf.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "funky-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920569930873737"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "mean_squared_log_error(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "inside-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0079768105438907"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "features = data_metadata[baseline_features]\n",
    "labels = data_metadata['like_count']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    \n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "prediction = rf.predict(X_test)\n",
    "mean_squared_log_error(y_test, rf.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cooperative-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986771649360644"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "mean_squared_log_error(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-address",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
